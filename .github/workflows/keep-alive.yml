name: Keep Streamlit App Alive

on:
  schedule:
    # Runs at 2, 16, 30, 44, and 58 minutes past the hour
    - cron: '2,16,30,44,58 * * * *'
  workflow_dispatch:

jobs:
  ping-and-verify:
    runs-on: ubuntu-latest
    steps:
    - name: Ping and Verify Streamlit App
      run: |
        # --- Stage 1: Resiliently Ping the App ---
        # We will try up to 3 times to get a successful HTTP 200 response.
        
        echo "üèÉ Stage 1: Pinging app to ensure it's reachable..."
        SUCCESS=false
        for i in {1..3}; do
          # The -L flag is CRUCIAL. It tells curl to follow any redirects (like the 303 you saw).
          # We capture only the HTTP status code.
          response_code=$(curl -L -s -o /dev/null -w "%{http_code}" --max-time 30 "https://etsa-survey.streamlit.app/")
          
          if [ "$response_code" -eq 200 ]; then
            echo "‚úÖ Attempt $i: Success! Received HTTP 200."
            SUCCESS=true
            break # Exit the loop on first success
          else
            echo "‚ö†Ô∏è Attempt $i: Failed. Received HTTP $response_code. Retrying in 5 seconds..."
            sleep 5
          fi
        done

        # --- Stage 2: Verify the Ping Succeeded ---
        # If after 3 attempts, we never got a 200, the app is truly down or broken.
        
        if ! $SUCCESS; then
          echo "‚ùå CRITICAL: Stage 1 Failed. The app did not respond with a 200 OK after 3 attempts."
          exit 1 # Fail the entire workflow
        fi

        # --- Stage 3: Verify App Content ---
        # A 200 OK is good, but it could still be serving the "sleep" page.
        # We must check the page content for the unique "sleep" message.

        echo "üîç Stage 3: Verifying app content to ensure it is not the sleep page..."
        
        # Define the unique text that ONLY appears on the "sleep" page.
        SLEEP_PAGE_TEXT="This app has gone to sleep"
        
        # Fetch the page content (again, with -L to follow redirects) and pipe it to grep.
        # `grep -q` is "quiet". It returns exit code 0 if the text is found, 1 if not.
        if curl -L -s --max-time 30 "https://etsa-survey.streamlit.app/" | grep -q "$SLEEP_PAGE_TEXT"; then
          # If grep finds the text, the app is asleep. This is a critical failure.
          echo "‚ùå CRITICAL: Stage 3 Failed. The app is serving the sleep page!"
          exit 1 # Fail the entire workflow
        else
          # If grep does NOT find the text, the app is awake and running properly.
          echo "‚úÖ SUCCESS: App is healthy and responsive. The sleep page was not detected."
        fi
